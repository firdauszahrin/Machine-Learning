{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c446aa9d-cf61-459f-a260-f14f70a46df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"methodology_201022.png\" width=\"978\" height=\"567\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import image module\n",
    "from IPython.display import Image\n",
    "\n",
    "# get the image\n",
    "Image(url=\"methodology_201022.png\", width=978, height=567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "733b5953-c982-456e-af03-46ecddff21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable debugging\n",
    "import cgitb\n",
    "cgitb.enable()\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45095924-ba16-44e8-af49-648821d12c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the start time\n",
    "st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "837b4e92-35e8-4c87-8a1d-01b563057007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data = \"sistem akan menyemak samada sistem telah dikonfigurasikan supaya menjana sat secara automatik selepas maklumbalas disimpan.\"\n",
    "#input_data = \"Sistem memproses maklumat dengan cepat dan pantas serta berintegriti.\"\n",
    "#input_data = \"Sistem memproses.\"\n",
    "input_data = \"Sistem memproses maklumat dengan pantas dan cepat sekali dengan kemahuan serta keupayaan masing-masing\"\n",
    "#input_data = \"Sistem memproses maklumat yang mempunyai antaramuka yang menarik dan ramah pengguna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3570d66-e500-4a75-9a63-65f67f02487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=re.sub(\"[$@&'.,!()#]\",\"\",input_data)\n",
    "input_data = s1.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e06f603-54cb-4c1b-868b-62ad9f17e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sistem memproses maklumat dengan pantas dan cepat sekali dengan kemahuan serta keupayaan masing-masing\n"
     ]
    }
   ],
   "source": [
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c28773e-42b4-4034-b83b-95edaba24ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya.pos\n",
    "model = malaya.pos.transformer(model = 'tiny-albert') #chose XLNET model : highest F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3790b3cd-f6a7-4292-a55f-2958ef97baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split so each word have their own string\n",
    "input_data = input_data.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a13bb43-a822-43d4-bf76-9a364dcc6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "newlen = len(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a69798eb-8cfc-4dd2-8b62-5f339964e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(newlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "037d8d63-46c2-413f-84ae-d949360d1e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This statement has more than 2 words.<br/>\n"
     ]
    }
   ],
   "source": [
    "if (newlen < 3):\n",
    "  print(\"This statement has less than 3 words. It is not a requirement.<br/>\") #less than 3 words is not a basic requirement\n",
    "\n",
    "else:\n",
    "  print(\"This statement has more than 2 words.<br/>\") #a basic requirement has 3 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e136abe-ae37-468f-bc99-226dcd5f34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_new = ' '.join(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "104d3f12-31e2-4a61-843c-02eded039be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sistem memproses maklumat dengan pantas dan cepat sekali dengan kemahuan serta keupayaan masing-masing\n"
     ]
    }
   ],
   "source": [
    "print(id_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a6753deb-23af-41e6-a858-7d4c38f50fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sistem', 'NOUN'), ('memproses', 'VERB'), ('maklumat', 'NOUN'), ('dengan', 'ADP'), ('pantas', 'ADJ'), ('dan', 'CCONJ'), ('cepat', 'ADJ'), ('sekali', 'ADV'), ('dengan', 'ADP'), ('kemahuan', 'NOUN'), ('serta', 'NOUN'), ('keupayaan', 'NOUN'), ('masing-masing', 'DET')]\n"
     ]
    }
   ],
   "source": [
    "pos = model.predict(id_new)\n",
    "\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7b1a7da9-99c2-45f0-b950-9a719e7e943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"amb_adj.png\" width=\"700\" height=\"85\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the image\n",
    "Image(url=\"amb_adj.png\", width=700, height=85)\n",
    "#Gleich et al. (2010) Ambiguity patterns with source and level of detection. Sources: AH=Ambiguity Handbook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f2994d6f-eb49-43d2-8951-257cbf6b0e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"amb_adj1.png\" width=\"450\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the image\n",
    "Image(url=\"amb_adj1.png\", width=450, height=250)\n",
    "#Warren (1988) AMBIGUITY AND VAGUENESS IN ADJECTIVES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b3a89f8-309f-47e6-9b42-8e9554b225f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br/><strong>This statement contains ADJECTIVE. Therefore, this statement is an Ambiguous Requirement.</strong><br/>\n"
     ]
    }
   ],
   "source": [
    "for adj in model.predict(id_new):\n",
    "    if (adj[1] == 'ADJ'):\n",
    "        print (\"<br/><strong>This statement contains ADJECTIVE. Therefore, this statement is an Ambiguous Requirement.</strong><br/>\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "af2984af-c5da-4884-9393-3ef816a1b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep the value contain the NOUN or VERB\n",
    "mod_pos=[]\n",
    "mod_rs=[]\n",
    "  \n",
    "for i in model.predict(id_new): \n",
    "    if (i[1] == 'NOUN' or i[1] == 'VERB'):\n",
    "        mod_pos.append(i[1])\n",
    "        mod_rs.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "702ab06c-19d6-4eb0-a2d3-9175fe15a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j:  0 limit: 3 <br/>\n",
      "1 ) sistem (NOUN) memproses (VERB) maklumat (NOUN).<br/>\n",
      "j:  1 limit: 3 <br/>\n",
      "j:  2 limit: 3 <br/>\n",
      "j:  3 limit: 3 <br/>\n"
     ]
    }
   ],
   "source": [
    "#Trigram pattern to check the basic Malay requirement structure\n",
    "#NOUN VERB NOUN (subject verb object)\n",
    "j=0\n",
    "x=0\n",
    "limit = len(mod_pos)-3\n",
    "  \n",
    "while j <= limit:\n",
    "    print(\"j: \",j, \"limit:\" ,limit,\"<br/>\")\n",
    "    if (mod_pos[j] == 'NOUN' and mod_pos[j+1] == 'VERB' and mod_pos[j+2] == 'NOUN'):\n",
    "        print((x+1),\") \"+mod_rs[j],\"(\"+mod_pos[j]+\") \"+mod_rs[j+1],\"(\"+mod_pos[j+1]+\") \"+mod_rs[j+2],\"(\"+mod_pos[j+2]+\").<br/>\")\n",
    "        x=x+1\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2388e7f3-520f-4656-ab45-bdffcaa24dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This statement complies with the basic requirement (Subject Verb Object).<br/>\n",
      "<br/><strong>Unambiguous Requirement.</strong><br/>\n",
      "<br/><table class=\"table table-bordered\"><thead><tr><th>#</th><th>Feature word(s)</th><th>No. of occurrence(s)</th></tr></thead><tbody>\n",
      "<tr><td> 1 </td><td> dan </td><td><center> 1 </center></td></tr>\n",
      "<tr><td> 2 </td><td> dengan </td><td><center> 2 </center></td></tr>\n",
      "<tr><td> 3 </td><td> maklumat </td><td><center> 1 </center></td></tr>\n",
      "<tr><td> 4 </td><td> serta </td><td><center> 1 </center></td></tr>\n",
      "<tr><td> 5 </td><td> sistem </td><td><center> 1 </center></td></tr>\n"
     ]
    }
   ],
   "source": [
    "if x > 0:\n",
    "        print(\"This statement complies with the basic requirement (Subject Verb Object).<br/>\")\n",
    "      \n",
    "        import pandas as pd\n",
    "        import sklearn as sk\n",
    "        import numpy as np\n",
    "        import math \n",
    "  \n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        from sklearn.feature_extraction.text import TfidfTransformer\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        \n",
    "        #load and read the data set (feature words & classes)\n",
    "        words = pd.read_csv('RS2_20%_SMOTE_TF.csv') \n",
    "        #words.head(5)\n",
    "        \n",
    "        #Create a dataframe for feature words \n",
    "        df = pd.DataFrame(words, columns=words.columns)\n",
    "  \n",
    "        #choose the feature words\n",
    "        fw = pd.DataFrame([df.columns[:-1]])\n",
    "        #print(fw)\n",
    "  \n",
    "        #training the data set\n",
    "        df['is_train'] = np.random.uniform(0, 1, len(df)) <= 1 #.99\n",
    "  \n",
    "        #create the fw in array format\n",
    "        fw_arr = []\n",
    "        for m in fw:\n",
    "            fw_arr.append([fw.iloc[0,m],0])\n",
    "            \n",
    "        c = 0\n",
    "        while c < len(fw_arr):\n",
    "            #print(fw_arr[c][0],\",\",fw_arr[c][1])\n",
    "            for z in input_data:\n",
    "                if fw_arr[c][0] == z: #compare the fw with input data (RS)\n",
    "                    fw_arr[c][1] = fw_arr[c][1] + 1  #count the terms\n",
    "                    #print(fw_arr[c][0],\",\",fw_arr[c][1])\n",
    "          \n",
    "            c=c+1\n",
    "        \n",
    "        #for x in fw_arr: #display the fw with term frequencies\n",
    "            #print(x)\n",
    "  \n",
    "        #Term Frequency for a requirement (input data)\n",
    "        word_fit=[]\n",
    "        v = 0\n",
    "  \n",
    "        while v < len(fw_arr):\n",
    "            #print(fw_arr[v][1])\n",
    "            word_fit.append(fw_arr[v][1])\n",
    "            \n",
    "            v=v+1\n",
    "  \n",
    "        #Term Frequency for a requirement (input)\n",
    "        #print(word_fit)\n",
    "  \n",
    "        #Create two new dataframes, one with the training rows, one with the test rows\n",
    "        train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "  \n",
    "        #Show the number of observations for the test and training dataframes\n",
    "        #print('Number of observations in the training data:', len(train))\n",
    "  \n",
    "        #Create a list of the feature words column's names\n",
    "        features = df.columns[:-2]\n",
    "        #print(features) #340 no. of FW\n",
    "  \n",
    "        #features\n",
    "        # train['CLASS'] contains the string value. Before we can use it,\n",
    "        # we need to convert each string into a numeric value. So, in this case there\n",
    "        # are 2 values, which have been coded as 0 (Y - unambiguity) or 1 (N - ambiguity).\n",
    "        y = train['class_name']\n",
    "  \n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from sklearn.model_selection import train_test_split\n",
    "  \n",
    "        #create Random Forest classifier\n",
    "        clf = RandomForestClassifier()\n",
    "  \n",
    "        # Train the classifier to take the training features and learn how they relate\n",
    "        # to the training y = (train['class_name'])\n",
    "        clf = clf.fit(train[features], y)\n",
    "  \n",
    "        #term frequencies of a requirement (input data) as a test features\n",
    "        test_features = np.array([word_fit])\n",
    "        test_features = test_features.reshape(1,-1)\n",
    "  \n",
    "        #prediction on test data based on trained data\n",
    "        prediction = clf.predict(test_features)\n",
    "  \n",
    "        #predict the output\n",
    "        prediction = prediction.tolist() \n",
    "  \n",
    "        #print(\"RandomForestClassifier predicts:\", prediction) # 0 (unambiguity) or 1 (ambiguity)\n",
    "  \n",
    "        #print('\"',ori_data,'\" is an')\n",
    "        #print('\"',id_new,'\" is an')\n",
    "  \n",
    "        if prediction[0] == 'Ambiguity':\n",
    "          print (\"<br/><strong>Ambiguous Requirement.</strong><br/>\")\n",
    "  \n",
    "        elif prediction[0] == 'Unambiguity':\n",
    "          print (\"<br/><strong>Unambiguous Requirement.</strong><br/>\")\n",
    "        \n",
    "        print('<br/><table class=\"table table-bordered\"><thead><tr><th>#</th><th>Feature word(s)</th><th>No. of occurrence(s)</th></tr></thead><tbody>')\n",
    "        k=0\n",
    "        zek=0\n",
    "        for s in fw_arr:\n",
    "          if fw_arr[k][1] > 0: #check the TF if exist more than 0\n",
    "            #print(\"<br/>\",fw_arr[k][0],\"-\",fw_arr[k][1]) #print the feature words and TF\n",
    "            zek=zek+1\n",
    "            print('<tr><td>',zek,'</td><td>',fw_arr[k][0],'</td><td><center>',fw_arr[k][1],'</center></td></tr>')\n",
    "          k=k+1\n",
    "\n",
    "else:\n",
    "    print(\"This statement does NOT comply with the basic requirement (Subject Verb Object). Hence, can't proceed to next stage.<br/>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "beddde13-acce-4421-a2e5-aa17b7955131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br/>Execution time: 6.44 seconds\n"
     ]
    }
   ],
   "source": [
    "#get the end time\n",
    "et = time.time()\n",
    "\n",
    "#get the execution time\n",
    "elapsed_time = et - st\n",
    "elapsed_time = \"{:.2f}\".format(elapsed_time)\n",
    "\n",
    "print('<br/>Execution time:',elapsed_time,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d837bd-7fff-4b79-880b-f181521d034e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
